ECBD 2021-23 Data for the INJ Benchmark
--
### Sources:
- [Onoe et al.](https://github.com/yasumasaonoe/ecbd)
- [Padmanabhan et al.](https://github.com/shankarp8/knowledge_distillation)

### Citations
```
@inproceedings{onoe-etal-2022-entity,
    title = "Entity Cloze By Date: What {LM}s Know About Unseen Entities",
    author = "Onoe, Yasumasa  and
      Zhang, Michael  and
      Choi, Eunsol  and
      Durrett, Greg",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    year = "2022",
}
```
```
@article{padmanabhan_2023_distill,
  title={Propagating Knowledge Updates in LMs Through Distillation},
  author={Shankar Padmanabhan and Yasumasa Onoe and Michael J.Q. Zhang and Greg Durrett and Eunsol Choi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}
```
